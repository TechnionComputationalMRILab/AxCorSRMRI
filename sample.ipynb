{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AxCorSRMRI sample notebook\n",
    "\n",
    "Self-Supervised Realistic Through-Plane MRI Super Resolution from Clinical 2D Axial and Coronal Acquisition.\n",
    "\n",
    "[For more information, please see the GitHub repository.](https://github.com/TechnionComputationalMRILab/AxCorSRMRI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:49:42.171144200Z",
     "start_time": "2024-06-02T05:49:14.970468300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Imports\n",
    "import torch\n",
    "assert torch.cuda.is_available()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Preprocess\n",
    "\n",
    "For first time users, please prepare your data accordingly. \n",
    "\n",
    "Create a where each case ID has two files - one for axial and one for coronal. The files should be in nifti format (.nii.gz). The files should be named as follows: \"case_id_AXIAL.nii.gz\" and \"case_id_CORONAL.nii.gz\".\n",
    "\n",
    "For example:\n",
    "```\n",
    "    - data_folder\n",
    "        - 1\n",
    "            - 1_AXIAL.nii.gz\n",
    "            - 1_CORONAL.nii.gz\n",
    "        - 2\n",
    "            - 2_AXIAL.nii.gz\n",
    "            - 2_CORONAL.nii.gz\n",
    "        - 3\n",
    "            - 3_AXIAL.nii.gz\n",
    "            - 3_CORONAL.nii.gz\n",
    "        - 4\n",
    "            - 4_AXIAL.nii.gz\n",
    "            - 4_CORONAL.nii.gz\n",
    "        - 5\n",
    "            - 5_AXIAL.nii.gz\n",
    "            - 5_CORONAL.nii.gz\n",
    "```\n",
    "\n",
    "Note that you need to have write permissions in the `data_folder` directory, as the code will write the preprocessed data in the same directory. The paths require a trailing slash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-01T16:58:16.242766Z",
     "start_time": "2024-06-01T16:57:54.210407700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Resample isotropic NIFTI coronal files\n",
    "# from axcorsrmri import resample_cases\n",
    "\n",
    "# path_to_data_files = r\"./data/\"\n",
    "# resample_cases(path_dir = path_to_data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:49:42.343514500Z",
     "start_time": "2024-06-02T05:49:42.185775600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # Create DB file with isotropic, coronal and axial files paths\n",
    "# from axcorsrmri import create_database\n",
    "\n",
    "# path_to_data_files = r\"./data/\"\n",
    "# create_database(\n",
    "#     path_to_data_files,\n",
    "#     train_frac=0.8,\n",
    "#     test_frac=0.1,\n",
    "#     num_folds=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Param Initializaion\n",
    "\n",
    "Here you can define the main parameters for the model training. Please refer to `Parameters_dictionary.txt` for more details of each parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:49:42.360005100Z",
     "start_time": "2024-06-02T05:49:42.360005100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 11:24:34.449234: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 11:24:34.581063: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-10 11:24:40.202889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-06-10 11:24:40.203181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-06-10 11:24:40.203213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from axcorsrmri import parser_setup\n",
    "\n",
    "override_args = {\n",
    "    \"path_to_set\": r\"./data/\",\n",
    "    \"path_to_results\": r\"./results/\",\n",
    "    \"amount_of_files\":20,\n",
    "    \"batch_size\":12,\n",
    "    \"loss\":\"L2\",\n",
    "    \"gpu_device\":\"0\",\n",
    "    \"amount_of_slices\":3,\n",
    "    \"title\":\"Test\",\n",
    "    \"total_samples\":100,\n",
    "    \"patch_size\":48,\n",
    "    \"epochs\": 20,\n",
    "    \"lr_g\":0.0001,\n",
    "    \"lr_d\": 0.0001,\n",
    "    \"scheduler\": \"const\",\n",
    "    \"max_workers_train\": 12,\n",
    "    \"max_workers_valid\": 30,\n",
    "    \"valid_batch_size\": 40,\n",
    "    \"adversarial_weight_I\": 0.02,\n",
    "    \"adversarial_weight_E\": 0.02,\n",
    "    \"d_optimizer_step_size\":40 ,\n",
    "    \"g_optimizer_step_size\": 160,\n",
    "    \"val_epoch\": 5,\n",
    "    \"image_save_freq_batch\": 100,\n",
    "    \"mage_save_freq_epoch\": 5,\n",
    "    \"save_tensor\":True,\n",
    "    \"save_nifti\":True\n",
    "}\n",
    "\n",
    "args = parser_setup(override_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Dataset Creation\n",
    "\n",
    "Initialize the training, validation and test datasets for the model training. In addition, the function creates a new folder in `path_to_results` to save the results and logs for tracking with tensorboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T05:51:43.042472900Z",
     "start_time": "2024-06-02T05:49:42.360005100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building and creating ESRT model from scratch.\n",
      "Loading the training and validation datasets...\n",
      "Loading the training and validation datasets...\n",
      "Loaded training and validation datasets successfully.\n",
      "Finished data preparation and parameters initialization.\n",
      "CPU times: user 2min 52s, sys: 55.2 s, total: 3min 47s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from axcorsrmri import initialize_data\n",
    "dl_train, dl_valid_lr, dl_valid_hr, dl_test_lr, dl_test_hr, result_dir, writer, config = initialize_data(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Training, validation, and testing\n",
    "Initalize the model and model parameters, and then train it on `dl_train` and validate it on `dl_valid_lr` and `dl_valid_hr`. After the training is done, it is tested on `dl_test_lr` and `dl_test_hr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n",
      "Built model successfully.\n",
      "Defining all optimizer functions...\n",
      "Defined all optimizer functions successfully.\n",
      "Defining all optimizer scheduler functions...\n",
      "Defined all optimizer scheduler functions successfully.\n",
      "Defining all loss functions...\n",
      "Defined all loss functions successfully.\n",
      "Starting model training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [15:32<?, ?it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "got error with the file ./data/2645718184330_20190102_cor_2D_FIESTA__isotropic.nii.gz_slice_269,index 264,size torch.Size([119, 1, 3, 48, 48])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/TrainingFunctions.py:704\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, InceptionV3_model, valid_dataloader_lr, valid_dataloader_hr, epoch, writer, step, result_dir, patch_size, max_size_lr, max_size_hr, config)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m     sr \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/ESRT/model/esrt.py:213\u001b[0m, in \u001b[0;36mESRT.forward\u001b[0;34m(self, x1, x2, test)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_blocks):\n\u001b[0;32m--> 213\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m     body_out\u001b[38;5;241m.\u001b[39mappend(x1)\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/ESRT/model/esrt.py:156\u001b[0m, in \u001b[0;36mUn.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m b,c,h,w \u001b[38;5;241m=\u001b[39m x3\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 156\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx3\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/ESRT/util/transformer.py:163\u001b[0m, in \u001b[0;36mMLABlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    161\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 163\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))\u001b[38;5;66;03m#self.drop_path(self.mlp(self.norm2(x)))\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/ESRT/util/transformer.py:118\u001b[0m, in \u001b[0;36mEffAttention.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    117\u001b[0m attn \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale   \u001b[38;5;66;03m#16*8*37*37\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[43mattn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:2\u001b[0m\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/main.py:469\u001b[0m, in \u001b[0;36mtraining_validation_test\u001b[0;34m(dl_train, dl_valid_lr, dl_valid_hr, dl_test_lr, dl_test_hr, result_dir, writer, args)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39mval_epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m    468\u001b[0m     start_val \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m--> 469\u001b[0m     fid, kid, step, max_size_lr, max_size_hr \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mInceptionV3_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_valid_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mdl_valid_hr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    471\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mresult_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m                                                                 \u001b[49m\u001b[43mmax_size_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_size_hr\u001b[49m\u001b[43m,\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    475\u001b[0m     end_val \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# print('Epoch val time-', time.strftime(\"%H:%M:%S\", time.gmtime(end_val - start_val)))\u001b[39;00m\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/TrainingFunctions.py:706\u001b[0m, in \u001b[0;36mvalidate\u001b[0;34m(model, InceptionV3_model, valid_dataloader_lr, valid_dataloader_hr, epoch, writer, step, result_dir, patch_size, max_size_lr, max_size_hr, config)\u001b[0m\n\u001b[1;32m    704\u001b[0m     sr \u001b[38;5;241m=\u001b[39m model(lr\u001b[38;5;241m.\u001b[39msqueeze())\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot error with the file \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,index \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m,size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(title,index,lr\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m    708\u001b[0m sr \u001b[38;5;241m=\u001b[39m sr\u001b[38;5;241m.\u001b[39msqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)[:patch_amount]\n\u001b[1;32m    710\u001b[0m lr_1_rec \u001b[38;5;241m=\u001b[39m recon_im_torch_rectangle_gaus(middle\u001b[38;5;241m.\u001b[39msqueeze(), \u001b[38;5;28mint\u001b[39m(size_lr[\u001b[38;5;241m0\u001b[39m]), \u001b[38;5;28mint\u001b[39m(size_lr[\u001b[38;5;241m1\u001b[39m]),\n\u001b[1;32m    711\u001b[0m                                                calculate_overlap(\u001b[38;5;28mint\u001b[39m(size_lr[\u001b[38;5;241m0\u001b[39m]), patch_size),\n\u001b[1;32m    712\u001b[0m                                                calculate_overlap(\u001b[38;5;28mint\u001b[39m(size_lr[\u001b[38;5;241m1\u001b[39m]), patch_size),\n\u001b[1;32m    713\u001b[0m                                                device \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m    714\u001b[0m                                                                                                 non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mException\u001b[0m: got error with the file ./data/2645718184330_20190102_cor_2D_FIESTA__isotropic.nii.gz_slice_269,index 264,size torch.Size([119, 1, 3, 48, 48])"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from axcorsrmri import training_validation_test\n",
    "training_validation_test(dl_train, dl_valid_lr, dl_valid_hr, dl_test_lr, dl_test_hr, result_dir, writer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Reconstruct SR Volumes\n",
    "Apply the SR model on all `isotropic` files in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from axcorsrmri import test_parser_setup\n",
    "\n",
    "override_args_test = {\n",
    "    \"path_to_set\": r\"./data/\",\n",
    "    \"path_to_results\": r\"./results/\",\n",
    "    \"path_to_trained_model\": r\"./Test_06_06_2024_11_47/\",\n",
    "    \"amount_of_files\":20,\n",
    "    \"batch_size\":12,\n",
    "    \"gpu_device\":\"0,1\",\n",
    "    \"amount_of_slices\":3,\n",
    "    \"title\":\"Test\",\n",
    "    \"save_tensor\":True,\n",
    "    \"save_nifti\":True,\n",
    "}\n",
    "\n",
    "test_args = test_parser_setup(override_args_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the dataset...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 9866575872 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maxcorsrmri\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m reconstruct_SR_volumes_in_folder\n\u001b[0;32m----> 3\u001b[0m \u001b[43mreconstruct_SR_volumes_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/main.py:692\u001b[0m, in \u001b[0;36mreconstruct_SR_volumes_in_folder\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;66;03m# print(\"config.multi_gpu - \", config.multi_gpu)\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# print(\"config.use_multi_gpu {}\".format(config.use_multi_gpu))\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;66;03m# if torch.cuda.is_available():\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[38;5;66;03m#     print('gpu count:', str(torch.cuda.device_count()))\u001b[39;00m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating the dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 692\u001b[0m list_test_slices,list_test_volume,test_file_to_idx \u001b[38;5;241m=\u001b[39m \u001b[43mmake_list_to_reconstract\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    693\u001b[0m istropic_dataset \u001b[38;5;241m=\u001b[39m DatasetCreation\u001b[38;5;241m.\u001b[39mCustomDataset_Test(slices\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_of_consecutive_slices, file_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28msorted\u001b[39m(list_test_slices),\n\u001b[1;32m    694\u001b[0m                                                    lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, file_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnifti\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    695\u001b[0m                                                    batch\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size, patch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpatch_size,\n\u001b[1;32m    696\u001b[0m                                                    use_db\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    697\u001b[0m                                                    list_volumes\u001b[38;5;241m=\u001b[39mlist_test_volume, file_to_idx\u001b[38;5;241m=\u001b[39mtest_file_to_idx)\n\u001b[1;32m    698\u001b[0m isotropic_dataloader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(dataset\u001b[38;5;241m=\u001b[39mistropic_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m    699\u001b[0m                                        num_workers\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mmax_workers_test,prefetch_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/DatasetCreation.py:561\u001b[0m, in \u001b[0;36mmake_list_to_reconstract\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    558\u001b[0m             list_of_files\u001b[38;5;241m.\u001b[39mappend(path_to_file)\n\u001b[1;32m    560\u001b[0m list_test_slices \u001b[38;5;241m=\u001b[39m create_patch_list(list_of_files, \u001b[38;5;241m0\u001b[39m, config\u001b[38;5;241m.\u001b[39mnum_of_consecutive_slices, patch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpatch_size,Rec_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 561\u001b[0m list_test_volume, test_file_to_idx \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_patch_list_and_volume_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_of_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                                                                       \u001b[49m\u001b[43mpatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43mRec_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m list_test_slices,list_test_volume,test_file_to_idx\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/DatasetCreation.py:416\u001b[0m, in \u001b[0;36mcreate_patch_list_and_volume_list\u001b[0;34m(list_files, train, patch_size, Rec_dir)\u001b[0m\n\u001b[1;32m    414\u001b[0m             list_LR_tensor\u001b[38;5;241m.\u001b[39mappend(temp_volume)\n\u001b[1;32m    415\u001b[0m         file_to_idx[list_files[j]] \u001b[38;5;241m=\u001b[39m j\n\u001b[0;32m--> 416\u001b[0m         list_LR_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mpad_vol_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_LR_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m list_LR_tensor, file_to_idx\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/tcmldrive/users/ang.a/AxCorSRMRI/DatasetCreation.py:362\u001b[0m, in \u001b[0;36mpad_vol_patches\u001b[0;34m(list_tensor)\u001b[0m\n\u001b[1;32m    360\u001b[0m         diff \u001b[38;5;241m=\u001b[39m max_patches \u001b[38;5;241m-\u001b[39m list_tensor[i][\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    361\u001b[0m         pad \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, diff)\n\u001b[0;32m--> 362\u001b[0m         list_tensor[i][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlist_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m list_tensor\n",
      "File \u001b[0;32m~/.conda/envs/axcorsrmri/lib/python3.10/site-packages/torch/nn/functional.py:4522\u001b[0m, in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   4515\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreplicate\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   4516\u001b[0m             \u001b[38;5;66;03m# Use slow decomp whose backward will be in terms of index_put.\u001b[39;00m\n\u001b[1;32m   4517\u001b[0m             \u001b[38;5;66;03m# importlib is required because the import cannot be top level\u001b[39;00m\n\u001b[1;32m   4518\u001b[0m             \u001b[38;5;66;03m# (cycle) and cannot be nested (TS doesn't support)\u001b[39;00m\n\u001b[1;32m   4519\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorch._decomp.decompositions\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39m_replication_pad(\n\u001b[1;32m   4520\u001b[0m                 \u001b[38;5;28minput\u001b[39m, pad\n\u001b[1;32m   4521\u001b[0m             )\n\u001b[0;32m-> 4522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at alloc_cpu.cpp:117] err == 0. DefaultCPUAllocator: can't allocate memory: you tried to allocate 9866575872 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "from axcorsrmri import reconstruct_SR_volumes_in_folder\n",
    "\n",
    "reconstruct_SR_volumes_in_folder(test_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
